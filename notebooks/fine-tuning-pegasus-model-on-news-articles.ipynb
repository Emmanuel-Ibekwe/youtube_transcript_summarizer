{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T14:15:59.549422Z",
     "iopub.status.busy": "2025-06-30T14:15:59.549144Z",
     "iopub.status.idle": "2025-06-30T14:16:04.745681Z",
     "shell.execute_reply": "2025-06-30T14:16:04.744849Z",
     "shell.execute_reply.started": "2025-06-30T14:15:59.549372Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.4-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Downloading evaluate-0.4.4-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fsspec, evaluate\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.9.0.13 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.4.0.6 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.10.19 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.4.40 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.9.5 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.9.41 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed evaluate-0.4.4 fsspec-2025.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets sentencepiece evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T14:16:04.747850Z",
     "iopub.status.busy": "2025-06-30T14:16:04.747623Z",
     "iopub.status.idle": "2025-06-30T14:16:04.752216Z",
     "shell.execute_reply": "2025-06-30T14:16:04.751452Z",
     "shell.execute_reply.started": "2025-06-30T14:16:04.747828Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T14:16:04.753115Z",
     "iopub.status.busy": "2025-06-30T14:16:04.752920Z",
     "iopub.status.idle": "2025-06-30T14:16:05.117929Z",
     "shell.execute_reply": "2025-06-30T14:16:05.117239Z",
     "shell.execute_reply.started": "2025-06-30T14:16:04.753099Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/kaggle/input/youtube-transcripts-and-summaries/youtube_transcripts_with_summaries.csv\")\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T14:16:05.119639Z",
     "iopub.status.busy": "2025-06-30T14:16:05.118650Z",
     "iopub.status.idle": "2025-06-30T14:16:06.823951Z",
     "shell.execute_reply": "2025-06-30T14:16:06.823404Z",
     "shell.execute_reply.started": "2025-06-30T14:16:05.119617Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7643a41560c0470ab57733a6bf8dfae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['url', 'title', 'news_channel', 'video_id', 'article', 'highlights'],\n",
       "        num_rows: 396\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['url', 'title', 'news_channel', 'video_id', 'article', 'highlights'],\n",
       "        num_rows: 45\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files=\"/kaggle/input/youtube-transcripts-and-summaries/youtube_transcripts_with_summaries.csv\")\n",
    "\n",
    "# Rename columns  \n",
    "dataset = dataset.rename_column(\"transcript\", \"article\")\n",
    "dataset = dataset.rename_column(\"summary\", \"highlights\")\n",
    "\n",
    "# Split into train and eval\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T14:16:06.826410Z",
     "iopub.status.busy": "2025-06-30T14:16:06.826062Z",
     "iopub.status.idle": "2025-06-30T14:16:06.831956Z",
     "shell.execute_reply": "2025-06-30T14:16:06.831078Z",
     "shell.execute_reply.started": "2025-06-30T14:16:06.826391Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bengaluru is facing heavy rains and flooding again, frustrating residents as the problem recurs yearly without solutions. Locals have turned to humor online, creating memes to cope. Meanwhile, news outlet First Post pledges accurate, verified reporting—owning past mistakes and promising transparency amid the noise of breaking news and misinformation.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][0][\"highlights\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T14:16:06.832867Z",
     "iopub.status.busy": "2025-06-30T14:16:06.832626Z",
     "iopub.status.idle": "2025-06-30T14:16:06.850284Z",
     "shell.execute_reply": "2025-06-30T14:16:06.849671Z",
     "shell.execute_reply.started": "2025-06-30T14:16:06.832852Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# dataset_samsum = load_dataset('samsum')\n",
    "# dataset_samsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T14:16:06.851066Z",
     "iopub.status.busy": "2025-06-30T14:16:06.850903Z",
     "iopub.status.idle": "2025-06-30T14:16:06.864708Z",
     "shell.execute_reply": "2025-06-30T14:16:06.864053Z",
     "shell.execute_reply.started": "2025-06-30T14:16:06.851053Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# pipe_out = pipe(dataset_samsum['test'][0][\"dialogue\"])\n",
    "# print('Summary')\n",
    "# print(pipe_out[0]['summary_text'].replace(\". <n>\", \".\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T14:16:06.865778Z",
     "iopub.status.busy": "2025-06-30T14:16:06.865500Z",
     "iopub.status.idle": "2025-06-30T14:16:06.878591Z",
     "shell.execute_reply": "2025-06-30T14:16:06.878028Z",
     "shell.execute_reply.started": "2025-06-30T14:16:06.865741Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from transformers import pipeline, set_seed\n",
    "\n",
    "# pipe = pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\")\n",
    "# pipe_out = pipe(dataset[\"test\"][0][\"article\"])\n",
    "# print(pipe_out[0][\"summary_text\"].replace(\". <n>\", \".\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T14:16:06.879303Z",
     "iopub.status.busy": "2025-06-30T14:16:06.879115Z",
     "iopub.status.idle": "2025-06-30T14:16:19.079128Z",
     "shell.execute_reply": "2025-06-30T14:16:19.078443Z",
     "shell.execute_reply.started": "2025-06-30T14:16:06.879286Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e1903dde754e92bc2d297a0a994ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/88.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6593e80e4fc94cdb99ffd29c41663693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3fa7e5a24164aa2b54f9f1c2ca6db66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762702960f4f43a3b9b0c961342adba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import PegasusTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"google/pegasus-cnn_dailymail\"\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T14:16:19.080461Z",
     "iopub.status.busy": "2025-06-30T14:16:19.080004Z",
     "iopub.status.idle": "2025-06-30T14:16:19.088453Z",
     "shell.execute_reply": "2025-06-30T14:16:19.087394Z",
     "shell.execute_reply.started": "2025-06-30T14:16:19.080442Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing entries at indices: []\n"
     ]
    }
   ],
   "source": [
    "missing_indices = [i for i, val in enumerate(dataset['train']['highlights']) if val is None or val.strip() == \"\"]\n",
    "print(f\"Missing entries at indices: {missing_indices}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T14:16:19.089856Z",
     "iopub.status.busy": "2025-06-30T14:16:19.089564Z",
     "iopub.status.idle": "2025-06-30T14:16:19.111023Z",
     "shell.execute_reply": "2025-06-30T14:16:19.110442Z",
     "shell.execute_reply.started": "2025-06-30T14:16:19.089832Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ddtZjbRno-Q'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][351]['video_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T14:16:19.112398Z",
     "iopub.status.busy": "2025-06-30T14:16:19.111849Z",
     "iopub.status.idle": "2025-06-30T14:16:20.973234Z",
     "shell.execute_reply": "2025-06-30T14:16:20.972430Z",
     "shell.execute_reply.started": "2025-06-30T14:16:19.112372Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6588333aa91749ecb4d43d2637ad720b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/396 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b311fefce99547b392a5114cdfb6889a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/45 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def convert_examples_to_features(example_batch):\n",
    "#     # print(f\"example_batch: {example_batch['article']}\")\n",
    "#     input_encodings = tokenizer(example_batch['article'], max_length=1024, truncation=True, padding=\"max_length\")\n",
    "\n",
    "#     with tokenizer.as_target_tokenizer():\n",
    "#         target_encodings = tokenizer(example_batch['highlights'], max_length=128, truncation=True, padding=\"max_length\")\n",
    "\n",
    "#     return {\"input_ids\": input_encodings['input_ids'],\n",
    "#             \"attention_mask\": input_encodings['attention_mask'],\n",
    "#            \"labels\": target_encodings['input_ids']}\n",
    "\n",
    "max_input_length = 1024\n",
    "max_target_length = 128\n",
    "\n",
    "# def tokenize_function(examples):\n",
    "#     model_inputs = tokenizer(\n",
    "#         text=examples[\"article\"],\n",
    "#         max_length=max_input_length,\n",
    "#         truncation=True,\n",
    "#         padding=\"max_length\"\n",
    "#     )\n",
    "#     with tokenizer.as_target_tokenizer():  # still works for now, but not future-proof\n",
    "#         labels = tokenizer(\n",
    "#             text_target=examples[\"highlights\"],\n",
    "#             max_length=max_target_length,\n",
    "#             truncation=True,\n",
    "#             padding=\"max_length\"\n",
    "#         )\n",
    "#     model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "#     return model_inputs\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        text=examples[\"article\"],\n",
    "        max_length=1024,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        text_target=examples[\"highlights\"],    # target (used as labels)\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T14:16:20.974155Z",
     "iopub.status.busy": "2025-06-30T14:16:20.973950Z",
     "iopub.status.idle": "2025-06-30T14:16:52.233573Z",
     "shell.execute_reply": "2025-06-30T14:16:52.232562Z",
     "shell.execute_reply.started": "2025-06-30T14:16:20.974140Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 14:16:23.034519: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751292983.225698      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751292983.290502      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de582f9cc9f4201a78f12b73fedfd1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dfd528afd5c4123b8df6481927b578e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ec79095ff441e5baf8926c59cf55fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import PegasusForConditionalGeneration\n",
    "\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T14:16:52.238322Z",
     "iopub.status.busy": "2025-06-30T14:16:52.237350Z",
     "iopub.status.idle": "2025-06-30T14:16:54.589869Z",
     "shell.execute_reply": "2025-06-30T14:16:54.588990Z",
     "shell.execute_reply.started": "2025-06-30T14:16:52.238291Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./pegasus-finetune-news\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=5,\n",
    "    predict_with_generate=True,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    push_to_hub=True,\n",
    "    fp16=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T14:16:54.591617Z",
     "iopub.status.busy": "2025-06-30T14:16:54.590954Z",
     "iopub.status.idle": "2025-06-30T14:17:01.551058Z",
     "shell.execute_reply": "2025-06-30T14:17:01.549868Z",
     "shell.execute_reply.started": "2025-06-30T14:16:54.591596Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rouge_score) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rouge_score) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rouge_score) (2024.2.0)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=5ebb9972096fe9e9fdebc926bc50428f8491e97a2d9c4ad625d23843100431e1\n",
      "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score\n",
      "Successfully installed rouge_score-0.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T14:17:01.552748Z",
     "iopub.status.busy": "2025-06-30T14:17:01.552421Z",
     "iopub.status.idle": "2025-06-30T14:17:02.884552Z",
     "shell.execute_reply": "2025-06-30T14:17:02.883634Z",
     "shell.execute_reply.started": "2025-06-30T14:17:01.552712Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0170c23031744f6b9b21b3f512dd8077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100 in labels as padding token\n",
    "    labels = [[(l if l != -100 else tokenizer.pad_token_id) for l in label] for label in labels]\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    result = {k: round(v * 100, 2) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T14:17:02.885596Z",
     "iopub.status.busy": "2025-06-30T14:17:02.885342Z",
     "iopub.status.idle": "2025-06-30T14:17:02.943627Z",
     "shell.execute_reply": "2025-06-30T14:17:02.942921Z",
     "shell.execute_reply.started": "2025-06-30T14:17:02.885570Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"api_token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T14:17:02.944580Z",
     "iopub.status.busy": "2025-06-30T14:17:02.944382Z",
     "iopub.status.idle": "2025-06-30T14:17:18.324871Z",
     "shell.execute_reply": "2025-06-30T14:17:18.324272Z",
     "shell.execute_reply.started": "2025-06-30T14:17:02.944559Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mugochiibekwe13\u001b[0m (\u001b[33mugochiibekwe13-federal-university-of-technology-owerri\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key=\"api_token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T14:17:18.326174Z",
     "iopub.status.busy": "2025-06-30T14:17:18.325565Z",
     "iopub.status.idle": "2025-06-30T14:54:16.663204Z",
     "shell.execute_reply": "2025-06-30T14:54:16.662524Z",
     "shell.execute_reply.started": "2025-06-30T14:17:18.326153Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/4240050231.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250630_141719-lxw6xwxh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ugochiibekwe13-federal-university-of-technology-owerri/huggingface/runs/lxw6xwxh' target=\"_blank\">./pegasus-finetune-news</a></strong> to <a href='https://wandb.ai/ugochiibekwe13-federal-university-of-technology-owerri/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ugochiibekwe13-federal-university-of-technology-owerri/huggingface' target=\"_blank\">https://wandb.ai/ugochiibekwe13-federal-university-of-technology-owerri/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ugochiibekwe13-federal-university-of-technology-owerri/huggingface/runs/lxw6xwxh' target=\"_blank\">https://wandb.ai/ugochiibekwe13-federal-university-of-technology-owerri/huggingface/runs/lxw6xwxh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 36:48, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.592600</td>\n",
       "      <td>6.343072</td>\n",
       "      <td>34.770000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>23.630000</td>\n",
       "      <td>23.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.182800</td>\n",
       "      <td>5.873182</td>\n",
       "      <td>36.330000</td>\n",
       "      <td>12.160000</td>\n",
       "      <td>24.510000</td>\n",
       "      <td>24.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.609700</td>\n",
       "      <td>5.218021</td>\n",
       "      <td>38.440000</td>\n",
       "      <td>13.110000</td>\n",
       "      <td>25.830000</td>\n",
       "      <td>25.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.818100</td>\n",
       "      <td>4.387918</td>\n",
       "      <td>38.560000</td>\n",
       "      <td>12.790000</td>\n",
       "      <td>26.360000</td>\n",
       "      <td>26.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.554700</td>\n",
       "      <td>4.004547</td>\n",
       "      <td>38.750000</td>\n",
       "      <td>12.770000</td>\n",
       "      <td>26.190000</td>\n",
       "      <td>26.190000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3339: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 128, 'min_length': 32, 'num_beams': 8, 'length_penalty': 0.8}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=990, training_loss=5.793119133843316, metrics={'train_runtime': 2217.045, 'train_samples_per_second': 0.893, 'train_steps_per_second': 0.447, 'total_flos': 5721139540131840.0, 'train_loss': 5.793119133843316, 'epoch': 5.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Result of the Training\n",
    "# Epoch\tTraining Loss\tValidation Loss\tRouge1\tRouge2\tRougel\tRougelsum\n",
    "# 1\t6.592600\t6.343072\t34.770000\t11.000000\t23.630000\t23.630000\n",
    "# 2\t6.182800\t5.873182\t36.330000\t12.160000\t24.510000\t24.510000\n",
    "# 3\t5.609700\t5.218021\t38.440000\t13.110000\t25.830000\t25.780000\n",
    "# 4\t4.818100\t4.387918\t38.560000\t12.790000\t26.360000\t26.310000\n",
    "# 5\t4.554700\t4.004547\t38.750000\t12.770000\t26.190000\t26.190000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T14:54:16.664621Z",
     "iopub.status.busy": "2025-06-30T14:54:16.664006Z",
     "iopub.status.idle": "2025-06-30T14:54:29.116737Z",
     "shell.execute_reply": "2025-06-30T14:54:29.116150Z",
     "shell.execute_reply.started": "2025-06-30T14:54:16.664603Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/ibk007/pegasus-finetune-news/commit/8c3bd5a3c959236f094b22bbc7cd4379948c7cd3', commit_message='End of training', commit_description='', oid='8c3bd5a3c959236f094b22bbc7cd4379948c7cd3', pr_url=None, repo_url=RepoUrl('https://huggingface.co/ibk007/pegasus-finetune-news', endpoint='https://huggingface.co', repo_type='model', repo_id='ibk007/pegasus-finetune-news'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T14:58:18.451563Z",
     "iopub.status.busy": "2025-06-30T14:58:18.451306Z",
     "iopub.status.idle": "2025-06-30T14:59:55.671469Z",
     "shell.execute_reply": "2025-06-30T14:59:55.670866Z",
     "shell.execute_reply.started": "2025-06-30T14:58:18.451548Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 01:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 4.004547119140625,\n",
       " 'eval_rouge1': 38.75,\n",
       " 'eval_rouge2': 12.77,\n",
       " 'eval_rougeL': 26.19,\n",
       " 'eval_rougeLsum': 26.19,\n",
       " 'eval_runtime': 97.2002,\n",
       " 'eval_samples_per_second': 0.463,\n",
       " 'eval_steps_per_second': 0.463,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# eval_results\n",
    "# {'eval_loss': 4.004547119140625,\n",
    "#  'eval_rouge1': 38.75,\n",
    "#  'eval_rouge2': 12.77,\n",
    "#  'eval_rougeL': 26.19,\n",
    "#  'eval_rougeLsum': 26.19,\n",
    "#  'eval_runtime': 97.2002,\n",
    "#  'eval_samples_per_second': 0.463,\n",
    "#  'eval_steps_per_second': 0.463,\n",
    "#  'epoch': 5.0\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T14:59:55.672694Z",
     "iopub.status.busy": "2025-06-30T14:59:55.672473Z",
     "iopub.status.idle": "2025-06-30T14:59:55.691942Z",
     "shell.execute_reply": "2025-06-30T14:59:55.691409Z",
     "shell.execute_reply.started": "2025-06-30T14:59:55.672678Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " eval_loss  eval_rouge1  eval_rouge2  eval_rougeL  eval_rougeLsum  eval_runtime  eval_samples_per_second  eval_steps_per_second  epoch\n",
      "  4.004547        38.75        12.77        26.19           26.19       97.2002                    0.463                  0.463    5.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([eval_results])\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T15:12:22.595294Z",
     "iopub.status.busy": "2025-06-30T15:12:22.594723Z",
     "iopub.status.idle": "2025-06-30T15:12:26.194053Z",
     "shell.execute_reply": "2025-06-30T15:12:26.193371Z",
     "shell.execute_reply.started": "2025-06-30T15:12:22.595241Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting youtube-transcript-api\n",
      "  Downloading youtube_transcript_api-1.1.0-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (0.7.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2025.4.26)\n",
      "Downloading youtube_transcript_api-1.1.0-py3-none-any.whl (485 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.7/485.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: youtube-transcript-api\n",
      "Successfully installed youtube-transcript-api-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install youtube-transcript-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T15:12:26.195777Z",
     "iopub.status.busy": "2025-06-30T15:12:26.195524Z",
     "iopub.status.idle": "2025-06-30T15:12:26.212589Z",
     "shell.execute_reply": "2025-06-30T15:12:26.211873Z",
     "shell.execute_reply.started": "2025-06-30T15:12:26.195756Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api._errors import TranscriptsDisabled, NoTranscriptFound, VideoUnavailable\n",
    "\n",
    "\n",
    "def fetch_transcript(video_id):\n",
    "    try:\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        full_text = \" \".join([entry['text'] for entry in transcript])\n",
    "        return full_text\n",
    "    except (TranscriptsDisabled, NoTranscriptFound, VideoUnavailable):\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T15:12:26.213799Z",
     "iopub.status.busy": "2025-06-30T15:12:26.213544Z",
     "iopub.status.idle": "2025-06-30T15:12:27.499010Z",
     "shell.execute_reply": "2025-06-30T15:12:27.498294Z",
     "shell.execute_reply.started": "2025-06-30T15:12:26.213772Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Remember when Donald Trump and Elon Musk were joined at the hip? It was cute while it lasted, you could say. Together, the two the two of them had it all. Money, power, and big egos. Musk bankrolled Trump\\'s election campaign. He gave him more than $250 million. Trump returned the favor with VIP access to the White House. He even created a government department for Musk. It was called Doge, the Department of Government Efficiency. Trump called Musk a visionary. Musk called Trump a friend. Like I said, it was a bromance for the ages. But like most great love stories, this one was not built to last. Elon Musk is now criticizing Donald Trump\\'s politics. You see, last week the US Congress approved a bill, Trump\\'s new tax bill. He calls it big and beautiful. That\\'s what he calls the tax bill, big and beautiful. It includes million-doll tax breaks, increased defense spending, and funding for a border wall. The bill is heading to the US Senate. Once it is passed by the Senate, it will massively increase the federal deficit. That\\'s the difference between what a government earns and what it spends. When the spending is more than the earning, there is a deficit. The American deficit is already huge. It currently stands at $1.83 trillion. $1.83 trillion. That\\'s their deficit. After this bill, it could increase by about $600 billion. Elon Musk does not like that. In a recent interview, he said, and I quote, \"I\\'m disappointed to see the massive spending bill, which increases the budget deficit and undermines the work that the Doge team is doing.\" So, Musk has called out the new bill. It increases the budget deficit and this goes against the Doge agenda. And that\\'s not all. Musk also took a shot at Trump\\'s word play. Let me quote again. I think a bill can be big or it can be beautiful, but I don\\'t know if it can be both. My personal opinion. Trump calls it big and beautiful. Musk says it can either be big or beautiful, not both. Either way, the bromance is cracking and not out of the blue. The murmurss began long ago, just days into the Trump presidency. Trump\\'s cabinet did not like Elon Musk. They thought he had too much power. Also, Musk\\'s Doge was not much of a hit. It did not manage to cut federal spending in a big way, but it did manage to upset a lot of people. Elon Musk was on thin ice, so he tried to tip the Wisconsin Supreme Court race. That did not work either. The Democrats won and Musk was suddenly persona non- grata. Meanwhile, his company Tesla was tanking. Sales nose died. Investors panicked and Musk finally remembered that he had a real job to do. He was supposed to be running a car company, not a country. So, he left the White House. They say it\\'s not a breakup. Both Trump and Musk insist that it\\'s not a breakup. But again, look at Musk\\'s recent interview. He says he will refocus on Tesla. No more political distractions. No more mega donations. In other words, the campaign cash tab is turning off. At least that\\'s the official line. But what triggered it? Was it a sudden epiphany or a presidential cold shoulder? It\\'s hard to say. The one thing is quite clear. This was inevitable. Elon Musk is a control freak in a room full of yesmen. And Trump is a yesman in a room full of mirrors. There\\'s only so much room for ego when two people believe that they are the main character. And let\\'s not forget Trump\\'s high attrition rate. In his first term as president, Donald Trump fired four national security advisers, three chiefs of staff, and two press secretaries in a span of just two years. And now we have this Musk episode. It\\'s a lesson for everyone really. Whether you\\'re a mega donor or a techmogul or an American ally, we have one thing to say to you. Don\\'t get too comfortable. One minute you\\'re flying to state dinners, the next you\\'re out. Because in Donald Trump\\'s world, loyalty is a one-way street. You\\'re only useful until you\\'re not. [Music] First Post now available in nine languages on [Music] YouTube. English 36ion, French, German, Hindi, Indonesian, Italian, Japanese, Portuguese, Spanish. [Music] Go to settings, click on audio track, and select the language of your choice. Be the first to know what\\'s happening around you in your first language. [Music] First post. [Music]'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://youtu.be/SxSS1UJtEAc?si=POQ72a1XaBATUXhV\n",
    "# https://www.youtube.com/watch?v=hshUpii9uqY\n",
    "\n",
    "transcript = fetch_transcript(\"SxSS1UJtEAc\")\n",
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T15:14:08.774604Z",
     "iopub.status.busy": "2025-06-30T15:14:08.773843Z",
     "iopub.status.idle": "2025-06-30T15:14:52.585363Z",
     "shell.execute_reply": "2025-06-30T15:14:52.584504Z",
     "shell.execute_reply.started": "2025-06-30T15:14:08.774578Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3faccfd25464451a95a67651c9734c0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b60294e33c5c4ffebe746f4a85c6c6ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0f9a88d9244ae0b24dc781ac5459bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/245 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1dc7487da824b3faf283e59e0e5e9b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1967fc5a2d574192864329a5e2d906ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c82176b45f4ca68c6a96c0ce798c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"ibk007/pegasus-finetune-news\")\n",
    "output = summarizer(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T15:14:59.105021Z",
     "iopub.status.busy": "2025-06-30T15:14:59.104748Z",
     "iopub.status.idle": "2025-06-30T15:14:59.110919Z",
     "shell.execute_reply": "2025-06-30T15:14:59.110216Z",
     "shell.execute_reply.started": "2025-06-30T15:14:59.105003Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \"Elon Musk and Donald Trump's bromance is ending, with Musk criticizing the president's new tax bill. He says it increases the deficit and undermines his government's efficiency. Both Trump and Musk insist it's not a breakup, but it's clear this was inevitable. In Trump's world, loyalty is a one-way street. Don't get too comfortable. One minute you're flying to state dinners, the next you're out. You're only useful until you're not.\"}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output\n",
    "\n",
    "/*\n",
    "[{'summary_text': \"Elon Musk and Donald Trump's bromance is ending, with Musk criticizing the president's new tax bill. He says it increases the deficit and undermines his government's efficiency. Both Trump and Musk insist it's not a breakup, but it's clear this was inevitable. In Trump's world, loyalty is a one-way street. Don't get too comfortable. One minute you're flying to state dinners, the next you're out. You're only useful until you're not.\"}]\n",
    "*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7772807,
     "sourceId": 12330522,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
